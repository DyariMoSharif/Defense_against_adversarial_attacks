{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc311d0-af7b-46b9-92af-03fd33272ba2",
   "metadata": {},
   "source": [
    "### Training per-digit RF verifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eace7fa7-7fc1-43bf-89e1-1423072c5ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1-NN verifiers (per digit) on strong multi-attack adversarials...\n",
      "\n",
      "→ Digit 0\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 611 adv\n",
      "    L2PGD...\n",
      "      collected 251 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 967 adv\n",
      "    L2DeepFool...\n",
      "      collected 770 adv\n",
      "    CW-L2...\n",
      "      collected 893 adv\n",
      "  Digit 0 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 1\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 2000 adv\n",
      "    L2PGD...\n",
      "      collected 1849 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1500 adv\n",
      "    L2DeepFool...\n",
      "      collected 1420 adv\n",
      "    CW-L2...\n",
      "      collected 1389 adv\n",
      "  Digit 1 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 2\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1094 adv\n",
      "    L2PGD...\n",
      "      collected 449 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1141 adv\n",
      "    L2DeepFool...\n",
      "      collected 938 adv\n",
      "    CW-L2...\n",
      "      collected 1050 adv\n",
      "  Digit 2 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 3\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 788 adv\n",
      "    L2PGD...\n",
      "      collected 428 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1057 adv\n",
      "    L2DeepFool...\n",
      "      collected 900 adv\n",
      "    CW-L2...\n",
      "      collected 1039 adv\n",
      "  Digit 3 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 4\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1702 adv\n",
      "    L2PGD...\n",
      "      collected 923 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1356 adv\n",
      "    L2DeepFool...\n",
      "      collected 1172 adv\n",
      "    CW-L2...\n",
      "      collected 1256 adv\n",
      "  Digit 4 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 5\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1206 adv\n",
      "    L2PGD...\n",
      "      collected 522 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1188 adv\n",
      "    L2DeepFool...\n",
      "      collected 1014 adv\n",
      "    CW-L2...\n",
      "      collected 1132 adv\n",
      "  Digit 5 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 6\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1247 adv\n",
      "    L2PGD...\n",
      "      collected 565 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1246 adv\n",
      "    L2DeepFool...\n",
      "      collected 992 adv\n",
      "    CW-L2...\n",
      "      collected 1123 adv\n",
      "  Digit 6 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 7\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1996 adv\n",
      "    L2PGD...\n",
      "      collected 1719 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1490 adv\n",
      "    L2DeepFool...\n",
      "      collected 1454 adv\n",
      "    CW-L2...\n",
      "      collected 1512 adv\n",
      "  Digit 7 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 8\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1306 adv\n",
      "    L2PGD...\n",
      "      collected 547 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1233 adv\n",
      "    L2DeepFool...\n",
      "      collected 1070 adv\n",
      "    CW-L2...\n",
      "      collected 1140 adv\n",
      "  Digit 8 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "→ Digit 9\n",
      "  PGD-style attacks:\n",
      "    LinfPGD...\n",
      "      collected 1933 adv\n",
      "    L2PGD...\n",
      "      collected 1176 adv\n",
      "  Minimization attacks on subset:\n",
      "    LinfDeepFool...\n",
      "      collected 1439 adv\n",
      "    L2DeepFool...\n",
      "      collected 1301 adv\n",
      "    CW-L2...\n",
      "      collected 1331 adv\n",
      "  Digit 9 verifier: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "\n",
      "✅ Trained rf verifiers for digits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import foolbox as fb\n",
    "from foolbox.attacks.base import MinimizationAttack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Setup ---\n",
    "os.makedirs(\"Models and Data splits\", exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Load data & model ---\n",
    "X_train, X_test, y_train, y_test = joblib.load(\n",
    "    \"Models and Data splits/data_[SCALED] Train_Test_Splits.pkl\"\n",
    ")\n",
    "model = torch.jit.load(\"Models and Data splits/lenet.pt\").to(device).eval()\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "# --- Attack parameters ---\n",
    "eps_inf = 0.1        \n",
    "eps_l2 = 1.0        \n",
    "pgd_steps = 100\n",
    "deepfool_steps = 1000\n",
    "cw_steps = 1000      \n",
    "max_train_per_digit = 2000\n",
    "\n",
    "eps_grid_linf = np.array([0.1, 0.2, 0.3], dtype=np.float32)\n",
    "eps_grid_l2   = np.array([0.5, 1.0, 2.0, 3.0], dtype=np.float32)\n",
    "\n",
    "# --- Define attacks ---\n",
    "attacks_eps = [\n",
    "    (\"LinfPGD\", fb.attacks.LinfPGD(steps=pgd_steps)),\n",
    "    (\"L2PGD\",   fb.attacks.L2PGD(steps=pgd_steps)),\n",
    "]\n",
    "\n",
    "attacks_minim = [\n",
    "    (\"LinfDeepFool\", fb.attacks.LinfDeepFoolAttack(steps=deepfool_steps)),\n",
    "    (\"L2DeepFool\",   fb.attacks.L2DeepFoolAttack(steps=deepfool_steps)),\n",
    "    (\"CW-L2\",        fb.attacks.L2CarliniWagnerAttack(steps=cw_steps)),\n",
    "]\n",
    "\n",
    "# --- Utilities ---\n",
    "\n",
    "def _to_numpy(x):\n",
    "    \"\"\"Convert torch / eagerpy / list-like to np.ndarray.\"\"\"\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    # torch tensor\n",
    "    if \"torch\" in str(type(x)):\n",
    "        return x.detach().cpu().numpy()\n",
    "    # eagerpy or similar\n",
    "    if hasattr(x, \"numpy\"):\n",
    "        return x.numpy()\n",
    "    # list or other sequence\n",
    "    return np.array(x)\n",
    "\n",
    "def _collect_from_pairs(pairs):\n",
    "    \"\"\"pairs: iterable of (adv, success). Returns (M, 784) or None.\"\"\"\n",
    "    collected = []\n",
    "    for adv_eps, suc_eps in pairs:\n",
    "        adv_np = _to_numpy(adv_eps)       # (..., C, H, W)\n",
    "        suc_np = _to_numpy(suc_eps).astype(bool)\n",
    "\n",
    "        if adv_np.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Ensure success mask is (N,)\n",
    "        if suc_np.ndim > 1:\n",
    "            suc_np = suc_np.reshape(suc_np.shape[0], -1).any(axis=1)\n",
    "\n",
    "        if adv_np.ndim == 5:\n",
    "            # (E, N, C, H, W) -> loop outside, so shouldn't happen here\n",
    "            raise RuntimeError(\"Unexpected 5D adv inside _collect_from_pairs\")\n",
    "        if adv_np.ndim != 4:\n",
    "            continue\n",
    "\n",
    "        if suc_np.shape[0] != adv_np.shape[0]:\n",
    "            # shape mismatch, skip this eps-level\n",
    "            continue\n",
    "\n",
    "        if suc_np.any():\n",
    "            sel = adv_np[suc_np]\n",
    "            collected.append(sel.reshape(sel.shape[0], -1))\n",
    "\n",
    "    if not collected:\n",
    "        return None\n",
    "    return np.vstack(collected)\n",
    "\n",
    "def collect_from_eps_attacks(attack, name, fmodel, images, labels, eps):\n",
    "    \"\"\"\n",
    "    For PGD-style attacks. Handles both array and list outputs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw, _, success = attack(fmodel, images, labels, epsilons=eps)\n",
    "\n",
    "        # Case 1: list of per-eps arrays\n",
    "        if isinstance(raw, list):\n",
    "            pairs = zip(raw, success)\n",
    "            return _collect_from_pairs(pairs)\n",
    "\n",
    "        # Case 2: single array; maybe with eps-dim\n",
    "        raw_np = _to_numpy(raw)\n",
    "        suc_np = _to_numpy(success).astype(bool)\n",
    "\n",
    "        if raw_np.ndim == 5:\n",
    "            # (E, N, C, H, W)\n",
    "            pairs = [(raw_np[ei], suc_np[ei]) for ei in range(raw_np.shape[0])]\n",
    "            return _collect_from_pairs(pairs)\n",
    "        elif raw_np.ndim == 4:\n",
    "            # (N, C, H, W)\n",
    "            return _collect_from_pairs([(raw_np, suc_np)])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [!] {name} failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def collect_from_minim_attack(attack, name, fmodel, images, labels):\n",
    "    \"\"\"\n",
    "    For MinimizationAttack subclasses (DeepFool, C&W).\n",
    "    In your Foolbox, these require epsilons and may return lists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if \"Linf\" in name:\n",
    "            eps_grid = eps_grid_linf\n",
    "        else:\n",
    "            eps_grid = eps_grid_l2\n",
    "\n",
    "        raw, _, success = attack(fmodel, images, labels, epsilons=eps_grid)\n",
    "\n",
    "        # Case 1: list-of-arrays\n",
    "        if isinstance(raw, list):\n",
    "            pairs = zip(raw, success)\n",
    "            return _collect_from_pairs(pairs)\n",
    "\n",
    "        # Case 2: array with eps-dim or not\n",
    "        raw_np = _to_numpy(raw)\n",
    "        suc_np = _to_numpy(success).astype(bool)\n",
    "\n",
    "        if raw_np.ndim == 5:\n",
    "            pairs = [(raw_np[ei], suc_np[ei]) for ei in range(raw_np.shape[0])]\n",
    "            return _collect_from_pairs(pairs)\n",
    "        elif raw_np.ndim == 4:\n",
    "            return _collect_from_pairs([(raw_np, suc_np)])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [!] {name} (MinimizationAttack) failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Training loop ---\n",
    "\n",
    "results = {}\n",
    "available_digits = []\n",
    "\n",
    "print(\"Training 1-NN verifiers (per digit) on strong multi-attack adversarials...\")\n",
    "\n",
    "for digit in range(10):\n",
    "    print(f\"\\n→ Digit {digit}\")\n",
    "\n",
    "    # Clean data for this digit\n",
    "    X_real_full = X_train[y_train == digit]\n",
    "    if len(X_real_full) == 0:\n",
    "        print(\"  ⚠️ No training samples, skipping.\")\n",
    "        continue\n",
    "\n",
    "    if max_train_per_digit is not None and len(X_real_full) > max_train_per_digit:\n",
    "        idx = np.random.choice(len(X_real_full), max_train_per_digit, replace=False)\n",
    "        X_real = X_real_full[idx]\n",
    "    else:\n",
    "        X_real = X_real_full\n",
    "\n",
    "    y_real = np.ones(len(X_real))\n",
    "\n",
    "    images = torch.tensor(X_real, dtype=torch.float32).view(-1, 1, 28, 28).to(device)\n",
    "    labels = torch.full((len(images),), digit, dtype=torch.long, device=device)\n",
    "\n",
    "    adv_list = []\n",
    "\n",
    "    # PGD-based attacks\n",
    "    print(\"  PGD-style attacks:\")\n",
    "    for name, atk in attacks_eps:\n",
    "        print(f\"    {name}...\")\n",
    "        use_eps = eps_l2 if \"L2\" in name else eps_inf\n",
    "        X_adv = collect_from_eps_attacks(atk, name, fmodel, images, labels, use_eps)\n",
    "        if X_adv is not None:\n",
    "            print(f\"      collected {X_adv.shape[0]} adv\")\n",
    "            adv_list.append(X_adv)\n",
    "        else:\n",
    "            print(\"      no successes\")\n",
    "\n",
    "    # Minimization attacks on subset\n",
    "    sub_n = min(500, len(images))\n",
    "    if sub_n > 0:\n",
    "        idx_sub = np.random.choice(len(images), sub_n, replace=False)\n",
    "        images_sub = images[idx_sub]\n",
    "        labels_sub = labels[idx_sub]\n",
    "\n",
    "        print(\"  Minimization attacks on subset:\")\n",
    "        for name, atk in attacks_minim:\n",
    "            print(f\"    {name}...\")\n",
    "            X_adv = collect_from_minim_attack(atk, name, fmodel, images_sub, labels_sub)\n",
    "            if X_adv is not None:\n",
    "                print(f\"      collected {X_adv.shape[0]} adv\")\n",
    "                adv_list.append(X_adv)\n",
    "            else:\n",
    "                print(\"      no successes\")\n",
    "\n",
    "    if not adv_list:\n",
    "        print(\"  ⚠️ No successful adversarials, skipping this digit.\")\n",
    "        continue\n",
    "\n",
    "    X_adv_all = np.vstack(adv_list)\n",
    "    y_adv_all = np.zeros(X_adv_all.shape[0])\n",
    "\n",
    "    # Balance clean vs adv\n",
    "    n_adv = X_adv_all.shape[0]\n",
    "    n_clean = min(2 * n_adv, X_real.shape[0])\n",
    "    if n_clean == 0:\n",
    "        print(\"  ⚠️ No clean after balancing, skipping.\")\n",
    "        continue\n",
    "\n",
    "    X_clean_sub = X_real[:n_clean]\n",
    "    y_clean_sub = y_real[:n_clean]\n",
    "\n",
    "    X_train_i = np.vstack([X_clean_sub, X_adv_all])\n",
    "    y_train_i = np.concatenate([y_clean_sub, y_adv_all])\n",
    "\n",
    "    #RF\n",
    "    rf=RandomForestClassifier(n_estimators=49)\n",
    "    rf.fit(X_train_i, y_train_i)\n",
    "    \n",
    "\n",
    "    out_path = f\"Models and Data splits/rf_digit_{digit}_pixels.joblib\"\n",
    "    joblib.dump(rf, out_path)\n",
    "    available_digits.append(digit)\n",
    "\n",
    "    # --- quick sanity check with strong PGD attacks ---\n",
    "    X_test_real = X_test[y_test == digit]\n",
    "    if len(X_test_real) == 0:\n",
    "        print(\"  ⚠️ No test samples.\")\n",
    "        continue\n",
    "\n",
    "    max_test = min(1000, len(X_test_real))\n",
    "    X_test_real = X_test_real[:max_test]\n",
    "\n",
    "    t_images = torch.tensor(X_test_real, dtype=torch.float32).view(-1, 1, 28, 28).to(device)\n",
    "    t_labels = torch.full((len(t_images),), digit, dtype=torch.long, device=device)\n",
    "\n",
    "    X_test_adv_list = []\n",
    "    for name, atk in attacks_eps:\n",
    "        use_eps = eps_l2 if \"L2\" in name else eps_inf\n",
    "        X_adv_t = collect_from_eps_attacks(atk, name, fmodel, t_images, t_labels, use_eps)\n",
    "        if X_adv_t is not None:\n",
    "            X_test_adv_list.append(X_adv_t)\n",
    "\n",
    "    if not X_test_adv_list:\n",
    "        print(\"  ⚠️ No test adversarials; skipping metrics.\")\n",
    "        continue\n",
    "\n",
    "    X_adv_t = np.vstack(X_test_adv_list)\n",
    "    n_t = min(len(X_test_real), X_adv_t.shape[0])\n",
    "\n",
    "    X_eval = np.vstack([X_test_real[:n_t], X_adv_t[:n_t]])\n",
    "    y_eval = np.concatenate([np.ones(n_t), np.zeros(n_t)])\n",
    "\n",
    "    y_pred = rf.predict(X_eval)\n",
    "\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    acc = accuracy_score(y_eval, y_pred)\n",
    "    prec = precision_score(y_eval, y_pred)\n",
    "    rec = recall_score(y_eval, y_pred)\n",
    "    f1 = f1_score(y_eval, y_pred)\n",
    "\n",
    "    results[digit] = dict(\n",
    "        confusion_matrix=cm,\n",
    "        accuracy=acc,\n",
    "        precision=prec,\n",
    "        recall=rec,\n",
    "        f1_score=f1,\n",
    "    )\n",
    "\n",
    "    print(f\"  Digit {digit} verifier: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "print(\"\\n✅ Trained rf verifiers for digits:\", available_digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fe1b0-db5d-45cf-bbf5-4172bad5138d",
   "metadata": {},
   "source": [
    "### Verification of adversarials from multiple attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342d4eee-7b4f-45b2-a341-e1a9b0cb8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LeNet model...\n",
      "Loading per-digit rf verifiers...\n",
      "  Loaded rf for digit 0\n",
      "  Loaded rf for digit 1\n",
      "  Loaded rf for digit 2\n",
      "  Loaded rf for digit 3\n",
      "  Loaded rf for digit 4\n",
      "  Loaded rf for digit 5\n",
      "  Loaded rf for digit 6\n",
      "  Loaded rf for digit 7\n",
      "  Loaded rf for digit 8\n",
      "  Loaded rf for digit 9\n",
      "Loading test samples for attack...\n",
      "\n",
      "Testing attacks with rf verification...\n",
      "\n",
      "→ FGSM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 2 (0.2%)\n",
      "\n",
      "→ PGD (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ PGD (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ C&W (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ DeepFool (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 10 (1.0%)\n",
      "\n",
      "=== Summary ===\n",
      "FGSM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L2): 2/1000 (0.2%) accepted\n",
      "PGD (L∞): 0/1000 (0.0%) accepted\n",
      "PGD (L2): 0/1000 (0.0%) accepted\n",
      "C&W (L2): 0/1000 (0.0%) accepted\n",
      "DeepFool (L2): 10/1000 (1.0%) accepted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import foolbox as fb\n",
    "\n",
    "# --- Setup ---\n",
    "os.environ['GIT_PYTHON_GIT_EXECUTABLE'] = r'C:\\Program Files\\Git\\bin\\git.exe'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load LeNet ---\n",
    "print(\"Loading LeNet model...\")\n",
    "model = torch.jit.load(\"Models and Data splits/lenet.pt\").to(device).eval()\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "# --- Load rf verifiers ---\n",
    "print(\"Loading per-digit rf verifiers...\")\n",
    "rfs = {}\n",
    "for digit in range(10):\n",
    "    path = f\"Models and Data splits/rf_digit_{digit}_pixels.joblib\"\n",
    "    if os.path.exists(path):\n",
    "        rfs[digit] = joblib.load(path)\n",
    "        print(f\"  Loaded rf for digit {digit}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ No verifier for digit {digit}, will skip those predictions.\")\n",
    "\n",
    "if not rfs:\n",
    "    raise RuntimeError(\"No rf verifiers found.\")\n",
    "\n",
    "# --- Load test samples for attack ---\n",
    "print(\"Loading test samples for attack...\")\n",
    "saved_data = torch.load(\"Models and Data splits/selected_samples_for_attack.pt\")\n",
    "images = saved_data[\"images\"].to(device)        # shape (N, 1, 28, 28), scaled [0,1]\n",
    "labels = saved_data[\"labels\"].to(device)\n",
    "\n",
    "# --- Attack configuration ---\n",
    "epsLinf = 0.1\n",
    "epsL2 = 1.0\n",
    "confidence_threshold = 0.90\n",
    "\n",
    "attacks = {\n",
    "    \"FGSM (L∞)\": fb.attacks.FGSM(),\n",
    "    \"BIM (L∞)\": fb.attacks.LinfBasicIterativeAttack(steps=50),\n",
    "    \"BIM (L2)\": fb.attacks.L2BasicIterativeAttack(steps=50),\n",
    "    \"PGD (L∞)\": fb.attacks.LinfPGD(steps=100),\n",
    "    \"PGD (L2)\": fb.attacks.L2PGD(steps=100),\n",
    "    \"C&W (L2)\": fb.attacks.L2CarliniWagnerAttack(steps=1000),\n",
    "    \"DeepFool (L2)\": fb.attacks.L2DeepFoolAttack(steps=500),\n",
    "}\n",
    "\n",
    "def verify_with_rf(image, predicted_digit):\n",
    "    \"\"\"\n",
    "    Use the corresponding per-digit rf to decide if this sample is 'clean-looking'.\n",
    "    Returns True if accepted, False if rejected.\n",
    "    \"\"\"\n",
    "    if predicted_digit not in rfs:\n",
    "        return False  # conservative: reject if no verifier available\n",
    "\n",
    "    rf = rfs[predicted_digit]\n",
    "    image_flat = image.detach().cpu().numpy().reshape(1, -1)\n",
    "    proba_clean = rf.predict_proba(image_flat)[0, 1]  # class 1 = clean\n",
    "    return proba_clean >= confidence_threshold\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = {name: {\"total\": 0, \"accepted\": 0} for name in attacks}\n",
    "\n",
    "print(\"\\nTesting attacks with rf verification...\")\n",
    "\n",
    "for name, attack in attacks.items():\n",
    "    print(f\"\\n→ {name}\")\n",
    "\n",
    "    eps = epsL2 if \"L2\" in name else epsLinf\n",
    "\n",
    "    # Generate adversarial examples\n",
    "    adv_raw, _, _ = attack(fmodel, images, labels, epsilons=eps)\n",
    "\n",
    "    # Handle possible shape (eps, N, C, H, W)\n",
    "    if adv_raw.ndim == 5:\n",
    "        adv_images = adv_raw[0]\n",
    "    else:\n",
    "        adv_images = adv_raw\n",
    "\n",
    "    adv_images = adv_images.to(device)\n",
    "    N = adv_images.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(adv_images)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    accepted = 0\n",
    "    for i in range(N):\n",
    "        if verify_with_rf(adv_images[i], int(preds[i].item())):\n",
    "            accepted += 1\n",
    "\n",
    "    results[name][\"total\"] = N\n",
    "    results[name][\"accepted\"] = accepted\n",
    "\n",
    "    rate = 100.0 * accepted / N if N > 0 else 0.0\n",
    "    print(f\"  Adversarial samples: {N}\")\n",
    "    print(f\"  Accepted by rf verifier: {accepted} ({rate:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for name, r in results.items():\n",
    "    N = r[\"total\"]\n",
    "    acc_rate = 100.0 * r[\"accepted\"] / N if N > 0 else 0.0\n",
    "    print(f\"{name}: {r['accepted']}/{N} ({acc_rate:.1f}%) accepted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10935ec2-0dc6-4c9e-bb5f-ad2473d7f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LeNet model...\n",
      "Loading per-digit rf verifiers...\n",
      "  Loaded rf for digit 0\n",
      "  Loaded rf for digit 1\n",
      "  Loaded rf for digit 2\n",
      "  Loaded rf for digit 3\n",
      "  Loaded rf for digit 4\n",
      "  Loaded rf for digit 5\n",
      "  Loaded rf for digit 6\n",
      "  Loaded rf for digit 7\n",
      "  Loaded rf for digit 8\n",
      "  Loaded rf for digit 9\n",
      "Loading test samples for attack...\n",
      "\n",
      "Testing attacks with rf verification...\n",
      "\n",
      "→ FGSM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ PGD (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ PGD (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ C&W (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ DeepFool (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 10 (1.0%)\n",
      "\n",
      "=== Summary ===\n",
      "FGSM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L2): 0/1000 (0.0%) accepted\n",
      "PGD (L∞): 0/1000 (0.0%) accepted\n",
      "PGD (L2): 0/1000 (0.0%) accepted\n",
      "C&W (L2): 0/1000 (0.0%) accepted\n",
      "DeepFool (L2): 10/1000 (1.0%) accepted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import foolbox as fb\n",
    "\n",
    "# --- Setup ---\n",
    "os.environ['GIT_PYTHON_GIT_EXECUTABLE'] = r'C:\\Program Files\\Git\\bin\\git.exe'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load LeNet ---\n",
    "print(\"Loading LeNet model...\")\n",
    "model = torch.jit.load(\"Models and Data splits/lenet.pt\").to(device).eval()\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "# --- Load rf verifiers ---\n",
    "print(\"Loading per-digit rf verifiers...\")\n",
    "rfs = {}\n",
    "for digit in range(10):\n",
    "    path = f\"Models and Data splits/rf_digit_{digit}_pixels.joblib\"\n",
    "    if os.path.exists(path):\n",
    "        rfs[digit] = joblib.load(path)\n",
    "        print(f\"  Loaded rf for digit {digit}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ No verifier for digit {digit}, will skip those predictions.\")\n",
    "\n",
    "if not rfs:\n",
    "    raise RuntimeError(\"No rf verifiers found.\")\n",
    "\n",
    "# --- Load test samples for attack ---\n",
    "print(\"Loading test samples for attack...\")\n",
    "saved_data = torch.load(\"Models and Data splits/selected_samples_for_attack.pt\")\n",
    "images = saved_data[\"images\"].to(device)        # shape (N, 1, 28, 28), scaled [0,1]\n",
    "labels = saved_data[\"labels\"].to(device)\n",
    "\n",
    "# --- Attack configuration ---\n",
    "epsLinf = 0.2\n",
    "epsL2 = 2.0\n",
    "confidence_threshold = 0.90\n",
    "\n",
    "attacks = {\n",
    "    \"FGSM (L∞)\": fb.attacks.FGSM(),\n",
    "    \"BIM (L∞)\": fb.attacks.LinfBasicIterativeAttack(steps=50),\n",
    "    \"BIM (L2)\": fb.attacks.L2BasicIterativeAttack(steps=50),\n",
    "    \"PGD (L∞)\": fb.attacks.LinfPGD(steps=100),\n",
    "    \"PGD (L2)\": fb.attacks.L2PGD(steps=100),\n",
    "    \"C&W (L2)\": fb.attacks.L2CarliniWagnerAttack(steps=1000),\n",
    "    \"DeepFool (L2)\": fb.attacks.L2DeepFoolAttack(steps=500),\n",
    "}\n",
    "\n",
    "def verify_with_rf(image, predicted_digit):\n",
    "    \"\"\"\n",
    "    Use the corresponding per-digit rf to decide if this sample is 'clean-looking'.\n",
    "    Returns True if accepted, False if rejected.\n",
    "    \"\"\"\n",
    "    if predicted_digit not in rfs:\n",
    "        return False  # conservative: reject if no verifier available\n",
    "\n",
    "    rf = rfs[predicted_digit]\n",
    "    image_flat = image.detach().cpu().numpy().reshape(1, -1)\n",
    "    proba_clean = rf.predict_proba(image_flat)[0, 1]  # class 1 = clean\n",
    "    return proba_clean >= confidence_threshold\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = {name: {\"total\": 0, \"accepted\": 0} for name in attacks}\n",
    "\n",
    "print(\"\\nTesting attacks with rf verification...\")\n",
    "\n",
    "for name, attack in attacks.items():\n",
    "    print(f\"\\n→ {name}\")\n",
    "\n",
    "    eps = epsL2 if \"L2\" in name else epsLinf\n",
    "\n",
    "    # Generate adversarial examples\n",
    "    adv_raw, _, _ = attack(fmodel, images, labels, epsilons=eps)\n",
    "\n",
    "    # Handle possible shape (eps, N, C, H, W)\n",
    "    if adv_raw.ndim == 5:\n",
    "        adv_images = adv_raw[0]\n",
    "    else:\n",
    "        adv_images = adv_raw\n",
    "\n",
    "    adv_images = adv_images.to(device)\n",
    "    N = adv_images.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(adv_images)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    accepted = 0\n",
    "    for i in range(N):\n",
    "        if verify_with_rf(adv_images[i], int(preds[i].item())):\n",
    "            accepted += 1\n",
    "\n",
    "    results[name][\"total\"] = N\n",
    "    results[name][\"accepted\"] = accepted\n",
    "\n",
    "    rate = 100.0 * accepted / N if N > 0 else 0.0\n",
    "    print(f\"  Adversarial samples: {N}\")\n",
    "    print(f\"  Accepted by rf verifier: {accepted} ({rate:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for name, r in results.items():\n",
    "    N = r[\"total\"]\n",
    "    acc_rate = 100.0 * r[\"accepted\"] / N if N > 0 else 0.0\n",
    "    print(f\"{name}: {r['accepted']}/{N} ({acc_rate:.1f}%) accepted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a617c9-9ae2-43ed-8025-eb436a3014b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LeNet model...\n",
      "Loading per-digit rf verifiers...\n",
      "  Loaded rf for digit 0\n",
      "  Loaded rf for digit 1\n",
      "  Loaded rf for digit 2\n",
      "  Loaded rf for digit 3\n",
      "  Loaded rf for digit 4\n",
      "  Loaded rf for digit 5\n",
      "  Loaded rf for digit 6\n",
      "  Loaded rf for digit 7\n",
      "  Loaded rf for digit 8\n",
      "  Loaded rf for digit 9\n",
      "Loading test samples for attack...\n",
      "\n",
      "Testing attacks with rf verification...\n",
      "\n",
      "→ FGSM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ BIM (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ PGD (L∞)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ PGD (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ C&W (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 0 (0.0%)\n",
      "\n",
      "→ DeepFool (L2)\n",
      "  Adversarial samples: 1000\n",
      "  Accepted by rf verifier: 10 (1.0%)\n",
      "\n",
      "=== Summary ===\n",
      "FGSM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L∞): 0/1000 (0.0%) accepted\n",
      "BIM (L2): 0/1000 (0.0%) accepted\n",
      "PGD (L∞): 0/1000 (0.0%) accepted\n",
      "PGD (L2): 0/1000 (0.0%) accepted\n",
      "C&W (L2): 0/1000 (0.0%) accepted\n",
      "DeepFool (L2): 10/1000 (1.0%) accepted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import foolbox as fb\n",
    "\n",
    "# --- Setup ---\n",
    "os.environ['GIT_PYTHON_GIT_EXECUTABLE'] = r'C:\\Program Files\\Git\\bin\\git.exe'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load LeNet ---\n",
    "print(\"Loading LeNet model...\")\n",
    "model = torch.jit.load(\"Models and Data splits/lenet.pt\").to(device).eval()\n",
    "fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "# --- Load rf verifiers ---\n",
    "print(\"Loading per-digit rf verifiers...\")\n",
    "rfs = {}\n",
    "for digit in range(10):\n",
    "    path = f\"Models and Data splits/rf_digit_{digit}_pixels.joblib\"\n",
    "    if os.path.exists(path):\n",
    "        rfs[digit] = joblib.load(path)\n",
    "        print(f\"  Loaded rf for digit {digit}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ No verifier for digit {digit}, will skip those predictions.\")\n",
    "\n",
    "if not rfs:\n",
    "    raise RuntimeError(\"No rf verifiers found.\")\n",
    "\n",
    "# --- Load test samples for attack ---\n",
    "print(\"Loading test samples for attack...\")\n",
    "saved_data = torch.load(\"Models and Data splits/selected_samples_for_attack.pt\")\n",
    "images = saved_data[\"images\"].to(device)        # shape (N, 1, 28, 28), scaled [0,1]\n",
    "labels = saved_data[\"labels\"].to(device)\n",
    "\n",
    "# --- Attack configuration ---\n",
    "epsLinf = 0.3\n",
    "epsL2 = 3.0\n",
    "confidence_threshold = 0.90\n",
    "\n",
    "attacks = {\n",
    "    \"FGSM (L∞)\": fb.attacks.FGSM(),\n",
    "    \"BIM (L∞)\": fb.attacks.LinfBasicIterativeAttack(steps=50),\n",
    "    \"BIM (L2)\": fb.attacks.L2BasicIterativeAttack(steps=50),\n",
    "    \"PGD (L∞)\": fb.attacks.LinfPGD(steps=100),\n",
    "    \"PGD (L2)\": fb.attacks.L2PGD(steps=100),\n",
    "    \"C&W (L2)\": fb.attacks.L2CarliniWagnerAttack(steps=1000),\n",
    "    \"DeepFool (L2)\": fb.attacks.L2DeepFoolAttack(steps=500),\n",
    "}\n",
    "\n",
    "def verify_with_rf(image, predicted_digit):\n",
    "    \"\"\"\n",
    "    Use the corresponding per-digit rf to decide if this sample is 'clean-looking'.\n",
    "    Returns True if accepted, False if rejected.\n",
    "    \"\"\"\n",
    "    if predicted_digit not in rfs:\n",
    "        return False  # conservative: reject if no verifier available\n",
    "\n",
    "    rf = rfs[predicted_digit]\n",
    "    image_flat = image.detach().cpu().numpy().reshape(1, -1)\n",
    "    proba_clean = rf.predict_proba(image_flat)[0, 1]  # class 1 = clean\n",
    "    return proba_clean >= confidence_threshold\n",
    "\n",
    "# --- Evaluation ---\n",
    "results = {name: {\"total\": 0, \"accepted\": 0} for name in attacks}\n",
    "\n",
    "print(\"\\nTesting attacks with rf verification...\")\n",
    "\n",
    "for name, attack in attacks.items():\n",
    "    print(f\"\\n→ {name}\")\n",
    "\n",
    "    eps = epsL2 if \"L2\" in name else epsLinf\n",
    "\n",
    "    # Generate adversarial examples\n",
    "    adv_raw, _, _ = attack(fmodel, images, labels, epsilons=eps)\n",
    "\n",
    "    # Handle possible shape (eps, N, C, H, W)\n",
    "    if adv_raw.ndim == 5:\n",
    "        adv_images = adv_raw[0]\n",
    "    else:\n",
    "        adv_images = adv_raw\n",
    "\n",
    "    adv_images = adv_images.to(device)\n",
    "    N = adv_images.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(adv_images)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    accepted = 0\n",
    "    for i in range(N):\n",
    "        if verify_with_rf(adv_images[i], int(preds[i].item())):\n",
    "            accepted += 1\n",
    "\n",
    "    results[name][\"total\"] = N\n",
    "    results[name][\"accepted\"] = accepted\n",
    "\n",
    "    rate = 100.0 * accepted / N if N > 0 else 0.0\n",
    "    print(f\"  Adversarial samples: {N}\")\n",
    "    print(f\"  Accepted by rf verifier: {accepted} ({rate:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for name, r in results.items():\n",
    "    N = r[\"total\"]\n",
    "    acc_rate = 100.0 * r[\"accepted\"] / N if N > 0 else 0.0\n",
    "    print(f\"{name}: {r['accepted']}/{N} ({acc_rate:.1f}%) accepted\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPUEnabled]",
   "language": "python",
   "name": "conda-env-GPUEnabled-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
